{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program!  In this notebook, you will learn how to control an agent in a more challenging environment, where the goal is to train a creature with four arms to walk forward.  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Crawler.app\"`\n",
    "- **Windows** (x86): `\"path/to/Crawler_Windows_x86/Crawler.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Crawler_Windows_x86_64/Crawler.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Crawler_Linux/Crawler.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Crawler_Linux/Crawler.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Crawler.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='./Crawler.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.353463500723592\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "count =0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        #break\n",
    "        pass\n",
    "    count +=1\n",
    "    if count > 1000:\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  ##Total memory length\n",
    "BATCH_SIZE = 128        ## minibatch size\n",
    "GAMMA = 0.99            ## discount factor\n",
    "#TAU = 1e-3              ## for soft update of target parameters\n",
    "#TAU = 5e-3              ## for soft update of target parameters tried this\n",
    "TAU = 5e-2              ## for soft update of target parameters\n",
    "LR_ACTOR = 1e-5         ## Learning Rate for Actor\n",
    "LR_CRITIC = 1e-5        ## Learning Rate for Critic\n",
    "WEIGHT_DECAY=0          ## Weight Decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if  torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actor Critic Models Definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for Uniform initialization of model layers\n",
    "## You may try normal initialization\n",
    "\n",
    "def init_hidden(layer):\n",
    "    input_size = layer.weight.data.size()[0]\n",
    "    lim = 1./np.sqrt(input_size)\n",
    "    return (-lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Actor \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    '''\n",
    "    Actor Model\n",
    "    '''\n",
    "    def __init__(self, state_size, action_size,hidden_size1=512,hidden_size2=256,seed =0 ):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build model\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed =torch.manual_seed(seed)\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        \n",
    "        self.FC1 = nn.Linear(self.state_size, self.hidden_size1)\n",
    "        self.FC2 = nn.Linear(self.hidden_size1, self.hidden_size2)\n",
    "        self.FC3 = nn.Linear(self.hidden_size2, self.action_size)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, state):\n",
    "        \n",
    "        x =  F.relu(self.FC1(state))\n",
    "        x =  F.relu(self.FC2(x))\n",
    "        x =  torch.tanh(self.FC3(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.FC1.weight.data.uniform_(*init_hidden(self.FC1))\n",
    "        self.FC2.weight.data.uniform_(*init_hidden(self.FC2))\n",
    "        self.FC3.weight.data.uniform_(-3e-3,3e-3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Critic\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    '''\n",
    "    Actor Model\n",
    "    '''\n",
    "    def __init__(self, state_size, action_size,hidden_size1=512,hidden_size2=256,seed =0 ):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build model\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed =torch.manual_seed(seed)\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        \n",
    "        self.FC1 = nn.Linear(self.state_size, self.hidden_size1)\n",
    "        self.FC2 = nn.Linear(self.hidden_size1+ self.action_size, self.hidden_size2)\n",
    "        self.FC3 = nn.Linear(self.hidden_size2, 1)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, state,action):\n",
    "        \n",
    "        xs =  F.relu(self.FC1(state))\n",
    "        x  =  torch.cat((xs, action),dim=1)\n",
    "        x =  F.relu(self.FC2(x))\n",
    "        x =  self.FC3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.FC1.weight.data.uniform_(*init_hidden(self.FC1))\n",
    "        self.FC2.weight.data.uniform_(*init_hidden(self.FC2))\n",
    "        self.FC3.weight.data.uniform_(-3e-3,3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed=0):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.count = 0\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        ##self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.experiences = namedtuple(\"Experience\", field_names = [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experiences(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "        ##self.count +=1\n",
    "        #print(self.count)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.size = size\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        ##dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        dx = self.theta * (self.mu - x) + self.sigma *np.random.standard_normal(self.size)\n",
    "        self.state = x + dx\n",
    "        ##return self.state Kaustav\n",
    "        ##return torch.tensor(self.state).float().to(device)\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"\n",
    "    Interacts with and learns from the environment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,state_size, action_size, n_agents,random_seed=0):\n",
    "        '''\n",
    "        Initialize parms\n",
    "        '''\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.n_agents = n_agents\n",
    "        self.seed = random_seed\n",
    "        self.actor_loss = []\n",
    "        self.critic_loss =[]\n",
    "        ## Actor Network\n",
    "        self.actor_local = Actor(self.state_size, self.action_size,seed=self.seed).to(device)\n",
    "        self.actor_target = Actor(self.state_size, self.action_size,seed=self.seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr = LR_ACTOR)\n",
    "        \n",
    "        ## Actor Network\n",
    "        self.critic_local = Critic(self.state_size, self.action_size,seed=self.seed).to(device)\n",
    "        self.critic_target = Critic(self.state_size, self.action_size,seed=self.seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr = LR_CRITIC,weight_decay=WEIGHT_DECAY)        \n",
    "        \n",
    "        # Noise process\n",
    "        self.noise = OUNoise((self.n_agents,action_size), random_seed)\n",
    "        \n",
    "        self.memory = ReplayBuffer(action_size,BUFFER_SIZE, BATCH_SIZE)\n",
    "    \n",
    "    def act(self, state, add_noise = True):\n",
    "        \n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        \n",
    "        self.actor_local.train()\n",
    "        \n",
    "        if add_noise:\n",
    "            #print(action.dtype)\n",
    "            #print(self.noise.sample().dtype)\n",
    "            #action += self.noise.sample().float().to(device)\n",
    "            action += self.noise.sample()\n",
    "        #if device == 'cpu':\n",
    "         #   return torch.clamp(action,-1,1)\n",
    "        #else:\n",
    "        #    return np.clip(action,-1,1)\n",
    "        ##return torch.clamp(action,-1,1)\n",
    "        return np.clip(action,-1,1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "        \n",
    "    def step(self,state, action, rewards , next_state , done):\n",
    "        ## The below line works for 1 agent \n",
    "        ##self.memory.add(state, action, rewards, next_state, done)\n",
    "        ## for multi agent\n",
    "        \n",
    "        for i in range(self.n_agents):\n",
    "            self.memory.add(state[i,:], action[i,:], rewards[i], next_state[i,:], done[i])\n",
    "\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            \n",
    "\n",
    "            self.learn(experiences,GAMMA)\n",
    "    \n",
    "    def learn(self,experiences,gamma):\n",
    "        \n",
    "        state, action, rewards, next_state, done = experiences\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        next_action = self.actor_target(next_state)\n",
    "        \n",
    "        q_target_next = self.critic_target(next_state, next_action)\n",
    "        # Compute Q targets for current states\n",
    "        q_target = rewards + gamma*q_target_next*(1- done)\n",
    "        \n",
    "        #Current Q value \n",
    "        q_current = self.critic_local(state, action)\n",
    "        ##TD Critic Loss\n",
    "        critic_loss = F.mse_loss(q_current,q_target)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.critic_local.parameters(), 0.5)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        self.critic_loss.append(critic_loss.item())\n",
    "        \n",
    "        \n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        action_pred = self.actor_local(state)\n",
    "        actor_loss = -self.critic_local(state, action_pred).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        ##clip gradient\n",
    "        nn.utils.clip_grad_norm_(self.actor_local.parameters(), 0.5)\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # Compute actor loss\n",
    "        #actions_pred = self.actor_local(state)\n",
    "        #actor_loss = -self.critic_local(state, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        #self.actor_optimizer.zero_grad()\n",
    "        #actor_loss.backward()\n",
    "        #self.actor_optimizer.step()\n",
    "        \n",
    "        self.actor_loss.append(actor_loss.item())\n",
    "        \n",
    "        #print('Actor Loss:',actor_loss.item(), 'Critic Loss',critic_loss.item() )\n",
    "    \n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)       \n",
    "\n",
    "    \n",
    "    def soft_update(self, local_model, target_model, tau=TAU):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (FC1): Linear(in_features=129, out_features=512, bias=True)\n",
      "  (FC2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (FC3): Linear(in_features=256, out_features=20, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (FC1): Linear(in_features=129, out_features=512, bias=True)\n",
      "  (FC2): Linear(in_features=532, out_features=256, bias=True)\n",
      "  (FC3): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# size of each action\n",
    "input_action_size = brain.vector_action_space_size\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "input_state_size = states.shape[1]\n",
    "\n",
    "# number of agents\n",
    "n_agents = len(env_info.agents)\n",
    "agent = Agent(input_state_size,input_action_size,n_agents)\n",
    "\n",
    "\n",
    "print(agent.actor_local)\n",
    "print(agent.critic_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loaded \tCritic Loaded\n",
      "Episode: \t531 \tScore: \t-0.58 \tAverage Score: \t-0.586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-14e3fbdee21b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m#print(env_info.local_done)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;31m#print(env_info.rewards)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mrewards\u001b[0m                          \u001b[1;31m# update the score (for each agent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-99fedc1191aa>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, rewards, next_state, done)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-99fedc1191aa>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, experiences, gamma)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# ----------------------- update target networks ----------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-99fedc1191aa>\u001b[0m in \u001b[0;36msoft_update\u001b[1;34m(self, local_model, target_model, tau)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \"\"\"\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_param\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mtarget_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlocal_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtarget_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_episodes=3000; max_t=1000; print_every=100;n_agents= len(env_info.agents);\n",
    "scores_deque = deque(maxlen = 100)\n",
    "scores = []\n",
    "\n",
    "##Load the trained actor and critic to continue training\n",
    "if os.path.exists('./checkpoint_actor_20.pth'):\n",
    "    agent.actor_local.load_state_dict(torch.load( './checkpoint_actor_20.pth'))\n",
    "    print('Actor Loaded ', end =\"\")\n",
    "\n",
    "\n",
    "if os.path.exists('./checkpoint_critic_20.pth'):\n",
    "    agent.critic_local.load_state_dict(torch.load( './checkpoint_critic_20.pth'))\n",
    "    print('\\tCritic Loaded', end= '\\n')\n",
    "\n",
    "\n",
    "best_score = -np.inf\n",
    "\n",
    "for episode in range(1, n_episodes+1):\n",
    "\n",
    "    env_info = env.reset(train_mode = True)[brain_name]\n",
    "    state = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    agent.reset()\n",
    "    score = np.zeros(n_agents)\n",
    "    ##print(episode)\n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state, add_noise=True)\n",
    "        #print(action)\n",
    "        env_info = env.step(action)[brain_name]           # send all actions to tne environment\n",
    "        next_state = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                        # get reward (for each agent)\n",
    "        done = env_info.local_done                        # see if episode finished\n",
    "\n",
    "        #print(episode)\n",
    "        #print(env_info.local_done)\n",
    "\n",
    "        agent.step(state, action, rewards, next_state, done)\n",
    "        #print(env_info.rewards)\n",
    "        score += rewards                          # update the score (for each agent)\n",
    "        state = next_state                                 # roll over states to next time step\n",
    "        if np.any( done ):\n",
    "            break\n",
    "\n",
    "    scores.append(np.mean(score))\n",
    "    scores_deque.append(np.mean(score))\n",
    "    print('\\rEpisode: \\t{} \\tScore: \\t{:.2f} \\tAverage Score: \\t{:.2f}'.format(episode, np.mean(score), \n",
    "                                                                                   np.mean(scores_deque)), end=\"\")  \n",
    "    #if (episode% print_every==0):\n",
    "    #    print('\\rEpisode: \\t{} \\tScore: \\t{:.2f} \\tAverage Score: \\t{:.2f}'.format(episode, np.mean(score), \n",
    "    #                                                                               np.mean(scores_deque)), end=\"\")  \n",
    "    \n",
    "    if np.mean(score) > best_score:\n",
    "        best_score= np.mean(score)\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_20.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_20.pth')\n",
    "    if (np.mean(scores_deque) >= 400):\n",
    "        print('\\nEnvironment solved in Episode: \\t{} \\tAverage Score: {:.2f}'.format(episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_20.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_20.pth')\n",
    "        break\n",
    "    ##print(episode)\n",
    "    #print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.title('Score achieved')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.title('Score achieved')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: \t0 \tScore: \t404.39\n",
      "Episode: \t1 \tScore: \t67.89\n",
      "Episode: \t2 \tScore: \t364.34\n",
      "Episode: \t3 \tScore: \t233.38\n",
      "Episode: \t4 \tScore: \t202.58\n"
     ]
    }
   ],
   "source": [
    "# test the trained agent\n",
    "agent = Agent(input_state_size,input_action_size,n_agents)\n",
    "agent.actor_local.load_state_dict(torch.load( './best/checkpoint_actor_20.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load( './best/checkpoint_critic_20.pth'))\n",
    "\n",
    "for episode in range(5):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]        \n",
    "    state = env_info.vector_observations       \n",
    "    score = np.zeros(n_agents)               \n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state, add_noise=False)                    \n",
    "        \n",
    "        env_info = env.step(action)[brain_name]        \n",
    "        next_state = env_info.vector_observations     \n",
    "        rewards = env_info.rewards       \n",
    "        dones = env_info.local_done\n",
    "        score += rewards\n",
    "        state = next_state\n",
    "\n",
    "        if np.any(dones):                              \n",
    "            break\n",
    "\n",
    "    print('Episode: \\t{} \\tScore: \\t{:.2f}'.format(episode, np.mean(score)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
